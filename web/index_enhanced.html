<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>E2E Voice Assistant - Enhanced</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            color: white;
        }

        .container {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 40px;
            max-width: 600px;
            width: 90%;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
        }

        h1 {
            text-align: center;
            margin-bottom: 10px;
            font-size: 2.5em;
        }

        .subtitle {
            text-align: center;
            opacity: 0.9;
            margin-bottom: 20px;
            font-size: 1em;
        }

        .features {
            display: flex;
            justify-content: center;
            gap: 15px;
            margin-bottom: 20px;
            flex-wrap: wrap;
        }

        .feature {
            background: rgba(255, 255, 255, 0.2);
            padding: 5px 12px;
            border-radius: 20px;
            font-size: 0.8em;
            font-weight: bold;
        }

        .status {
            background: rgba(255, 255, 255, 0.2);
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 15px;
            text-align: center;
        }

        .status.connected {
            background: rgba(76, 175, 80, 0.3);
        }

        .status.disconnected {
            background: rgba(244, 67, 54, 0.3);
        }

        .vad-status {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            padding: 10px;
            margin-bottom: 15px;
            text-align: center;
            font-size: 0.9em;
            transition: all 0.3s ease;
        }

        .vad-status.listening {
            background: rgba(33, 150, 243, 0.3);
        }

        .vad-status.speaking {
            background: rgba(255, 152, 0, 0.4);
            animation: pulse 1s infinite;
        }

        .vad-status.processing {
            background: rgba(156, 39, 176, 0.3);
            animation: pulse 0.8s infinite;
        }

        @keyframes pulse {
            0% { opacity: 0.7; transform: scale(1); }
            50% { opacity: 1; transform: scale(1.02); }
            100% { opacity: 0.7; transform: scale(1); }
        }

        .controls {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin: 20px 0;
        }

        button {
            background: white;
            color: #667eea;
            border: none;
            border-radius: 50%;
            width: 80px;
            height: 80px;
            font-size: 24px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
        }

        button:hover {
            transform: scale(1.1);
            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.3);
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        button.active {
            background: #4caf50;
            color: white;
            animation: activeButton 1.5s infinite;
        }

        @keyframes activeButton {
            0% { box-shadow: 0 0 0 0 rgba(76, 175, 80, 0.7); }
            70% { box-shadow: 0 0 0 15px rgba(76, 175, 80, 0); }
            100% { box-shadow: 0 0 0 0 rgba(76, 175, 80, 0); }
        }

        .volume-meter {
            height: 6px;
            background: rgba(255, 255, 255, 0.2);
            border-radius: 3px;
            margin: 15px 0;
            overflow: hidden;
        }

        .volume-bar {
            height: 100%;
            background: linear-gradient(90deg, #4caf50, #ffeb3b, #ff9800, #f44336);
            width: 0%;
            transition: width 0.1s ease;
        }

        .transcript {
            background: rgba(0, 0, 0, 0.2);
            border-radius: 10px;
            padding: 20px;
            min-height: 200px;
            max-height: 350px;
            margin-top: 20px;
            overflow-y: auto;
        }

        .message {
            margin: 12px 0;
            padding: 12px;
            border-radius: 10px;
            animation: fadeIn 0.3s ease;
        }

        .user-message {
            background: rgba(102, 126, 234, 0.3);
            text-align: right;
            margin-left: 20px;
        }

        .assistant-message {
            background: rgba(118, 75, 162, 0.3);
            text-align: left;
            margin-right: 20px;
        }

        .system-message {
            background: rgba(96, 125, 139, 0.3);
            text-align: center;
            font-style: italic;
            opacity: 0.8;
            font-size: 0.9em;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .mode-toggle {
            display: flex;
            justify-content: center;
            gap: 10px;
            margin: 15px 0;
        }

        .mode-btn {
            background: rgba(255, 255, 255, 0.2);
            color: white;
            border: none;
            padding: 8px 16px;
            border-radius: 20px;
            cursor: pointer;
            font-size: 0.8em;
            transition: all 0.3s ease;
        }

        .mode-btn.active {
            background: rgba(76, 175, 80, 0.6);
        }

        .tech-info {
            text-align: center;
            margin-top: 20px;
            font-size: 0.8em;
            opacity: 0.7;
            border-top: 1px solid rgba(255, 255, 255, 0.2);
            padding-top: 15px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è E2E Voice Assistant</h1>
        <p class="subtitle">Enhanced with VAD & Interruption</p>

        <div class="features">
            <div class="feature">üéØ Auto VAD</div>
            <div class="feature">üîÑ Interruption</div>
            <div class="feature">üì¶ Audio Buffer</div>
            <div class="feature">üí¨ Context</div>
        </div>

        <div id="status" class="status disconnected">
            <span id="statusText">Disconnected</span>
        </div>

        <div id="vadStatus" class="vad-status">
            <span id="vadText">üîå Click Connect to activate VAD</span>
        </div>

        <div class="mode-toggle">
            <button id="vadModeBtn" class="mode-btn active">VAD Mode</button>
            <button id="pushModeBtn" class="mode-btn">Push-to-Talk</button>
        </div>

        <div class="controls">
            <button id="connectBtn" title="Connect">
                üîå
            </button>
            <button id="talkBtn" disabled title="Push to Talk (Legacy)" style="display: none;">
                üé§
            </button>
        </div>

        <div class="volume-meter">
            <div id="volumeBar" class="volume-bar"></div>
        </div>

        <div class="transcript" id="transcript">
            <div class="system-message">
                üöÄ Enhanced E2E Voice Assistant<br>
                Click Connect to start VAD-powered conversation
            </div>
        </div>

        <div class="tech-info">
            <strong>Pipeline:</strong> Continuous Audio ‚Üí VAD ‚Üí Whisper ASR ‚Üí LLaMA 3.3 70B ‚Üí Speech5 TTS<br>
            <span id="latency" style="color: #4caf50;"></span>
        </div>
    </div>

    <script>
        class EnhancedVoiceAssistant {
            constructor() {
                this.ws = null;
                this.mediaStream = null;
                this.audioContext = null;
                this.processor = null;
                this.isConnected = false;
                this.vadMode = true;  // Default to VAD mode
                this.isTalking = false;
                this.audioChunks = [];
                this.currentAudio = null;  // Track current playing audio
                this.audioQueue = [];      // Queue to prevent multiple audio playing

                this.connectBtn = document.getElementById('connectBtn');
                this.talkBtn = document.getElementById('talkBtn');
                this.vadModeBtn = document.getElementById('vadModeBtn');
                this.pushModeBtn = document.getElementById('pushModeBtn');
                this.statusEl = document.getElementById('status');
                this.statusText = document.getElementById('statusText');
                this.vadStatus = document.getElementById('vadStatus');
                this.vadText = document.getElementById('vadText');
                this.transcript = document.getElementById('transcript');
                this.volumeBar = document.getElementById('volumeBar');

                this.setupEventListeners();
            }

            setupEventListeners() {
                this.connectBtn.addEventListener('click', () => this.toggleConnection());

                this.vadModeBtn.addEventListener('click', () => this.setMode('vad'));
                this.pushModeBtn.addEventListener('click', () => this.setMode('push'));

                // Push-to-talk events
                this.talkBtn.addEventListener('mousedown', () => this.startTalking());
                this.talkBtn.addEventListener('mouseup', () => this.stopTalking());
                this.talkBtn.addEventListener('mouseleave', () => this.stopTalking());

                // Touch events for mobile
                this.talkBtn.addEventListener('touchstart', (e) => {
                    e.preventDefault();
                    this.startTalking();
                });
                this.talkBtn.addEventListener('touchend', (e) => {
                    e.preventDefault();
                    this.stopTalking();
                });
            }

            setMode(mode) {
                this.vadMode = (mode === 'vad');

                if (this.vadMode) {
                    this.vadModeBtn.classList.add('active');
                    this.pushModeBtn.classList.remove('active');
                    this.talkBtn.style.display = 'none';
                } else {
                    this.vadModeBtn.classList.remove('active');
                    this.pushModeBtn.classList.add('active');
                    this.talkBtn.style.display = 'block';
                }

                if (this.isConnected) {
                    this.startAudioProcessing();
                }
            }

            async toggleConnection() {
                if (this.isConnected) {
                    this.disconnect();
                } else {
                    await this.connect();
                }
            }

            async connect() {
                try {
                    // Get user media
                    this.mediaStream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            echoCancellation: true,
                            noiseSuppression: true,
                            sampleRate: 16000,
                            autoGainControl: true
                        }
                    });

                    // Setup audio context
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: 16000
                    });

                    // Connect to WebSocket
                    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                    const wsUrl = `${protocol}//${window.location.host}/ws`;
                    this.ws = new WebSocket(wsUrl);

                    this.ws.onopen = () => {
                        this.isConnected = true;
                        this.updateStatus('Connected', true);
                        this.connectBtn.innerHTML = 'üî¥';
                        this.talkBtn.disabled = false;
                        this.addMessage('System', '‚úÖ Connected to Enhanced Voice Assistant');
                        this.startAudioProcessing();
                    };

                    this.ws.onclose = () => {
                        this.disconnect();
                    };

                    this.ws.onerror = (error) => {
                        console.error('WebSocket error:', error);
                        this.addMessage('System', 'Connection error');
                        this.disconnect();
                    };

                    this.ws.onmessage = (event) => {
                        this.handleMessage(event.data);
                    };

                } catch (error) {
                    console.error('Failed to connect:', error);
                    this.addMessage('System', 'Failed to access microphone');
                }
            }

            disconnect() {
                this.stopAudioProcessing();

                if (this.ws) {
                    this.ws.close();
                    this.ws = null;
                }

                if (this.mediaStream) {
                    this.mediaStream.getTracks().forEach(track => track.stop());
                    this.mediaStream = null;
                }

                if (this.audioContext) {
                    this.audioContext.close();
                    this.audioContext = null;
                }

                this.isConnected = false;
                this.updateStatus('Disconnected', false);
                this.updateVADStatus('üîå Click Connect to activate');
                this.connectBtn.innerHTML = 'üîå';
                this.talkBtn.disabled = true;
                this.updateVolume(0);
            }

            startAudioProcessing() {
                if (!this.isConnected || !this.mediaStream) return;

                const source = this.audioContext.createMediaStreamSource(this.mediaStream);
                this.processor = this.audioContext.createScriptProcessor(1024, 1, 1);

                source.connect(this.processor);
                this.processor.connect(this.audioContext.destination);

                if (this.vadMode) {
                    this.updateVADStatus('üé§ VAD Active - Speak naturally!');

                    this.processor.onaudioprocess = (e) => {
                        if (!this.isConnected || !this.ws || this.ws.readyState !== WebSocket.OPEN) return;

                        const inputData = e.inputBuffer.getChannelData(0);

                        // Calculate volume for visualization
                        let sum = 0;
                        for (let i = 0; i < inputData.length; i++) {
                            sum += Math.abs(inputData[i]);
                        }
                        const volume = sum / inputData.length;
                        this.updateVolume(volume * 300);

                        // Convert to 16-bit PCM and send continuously
                        const pcm16 = new Int16Array(inputData.length);
                        for (let i = 0; i < inputData.length; i++) {
                            pcm16[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
                        }

                        // Send audio chunk to server for VAD processing
                        const audioBase64 = btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)));
                        this.ws.send(JSON.stringify({
                            type: 'audio_chunk',
                            data: audioBase64
                        }));
                    };
                }
            }

            stopAudioProcessing() {
                if (this.processor) {
                    this.processor.disconnect();
                    this.processor = null;
                }
                this.updateVolume(0);
            }

            // Legacy push-to-talk methods
            async startTalking() {
                if (!this.isConnected || this.vadMode || this.isTalking) return;

                this.isTalking = true;
                this.talkBtn.classList.add('active');
                this.audioChunks = [];

                this.updateVADStatus('üé§ Recording...');
                this.startRecording();
            }

            stopTalking() {
                if (!this.isTalking || this.vadMode) return;

                this.isTalking = false;
                this.talkBtn.classList.remove('active');
                this.updateVADStatus('üì§ Processing...');

                if (this.processor) {
                    this.processor.disconnect();
                    this.processor = null;
                }

                this.updateVolume(0);

                // Send recorded audio
                if (this.audioChunks.length > 0) {
                    const totalLength = this.audioChunks.reduce((sum, chunk) => sum + chunk.length, 0);
                    const combinedAudio = new Int16Array(totalLength);
                    let offset = 0;

                    for (const chunk of this.audioChunks) {
                        combinedAudio.set(chunk, offset);
                        offset += chunk.length;
                    }

                    const wavBuffer = this.createWavFile(combinedAudio, 16000);
                    const base64 = btoa(String.fromCharCode(...new Uint8Array(wavBuffer)));

                    if (this.ws && this.ws.readyState === WebSocket.OPEN) {
                        this.ws.send(JSON.stringify({
                            type: 'audio',
                            data: base64
                        }));
                    }
                }
            }

            startRecording() {
                const source = this.audioContext.createMediaStreamSource(this.mediaStream);
                this.processor = this.audioContext.createScriptProcessor(4096, 1, 1);

                source.connect(this.processor);
                this.processor.connect(this.audioContext.destination);

                this.processor.onaudioprocess = (e) => {
                    if (!this.isTalking) return;

                    const inputData = e.inputBuffer.getChannelData(0);

                    // Calculate volume
                    let sum = 0;
                    for (let i = 0; i < inputData.length; i++) {
                        sum += Math.abs(inputData[i]);
                    }
                    const volume = sum / inputData.length;
                    this.updateVolume(volume * 500);

                    // Convert to 16-bit PCM and accumulate
                    const pcm16 = new Int16Array(inputData.length);
                    for (let i = 0; i < inputData.length; i++) {
                        pcm16[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
                    }
                    this.audioChunks.push(pcm16);
                };
            }

            handleMessage(data) {
                try {
                    const message = JSON.parse(data);

                    switch (message.type) {
                        case 'connection_status':
                            this.addMessage('System', message.message);
                            break;
                        case 'vad_status':
                            this.updateVADStatus(message.message);
                            if (message.status) {
                                this.vadStatus.className = `vad-status ${message.status}`;
                            }
                            break;
                        case 'processing_status':
                            this.updateVADStatus(this.getProcessingMessage(message.status));
                            this.vadStatus.className = `vad-status ${message.status}`;
                            break;
                        case 'transcription':
                            this.addMessage('You', message.text);
                            break;
                        case 'response':
                            this.addMessage('Assistant', message.text);
                            break;
                        case 'audio_response':
                            this.playAudio(message.data, message.content_type, message.size);
                            break;
                        case 'interruption':
                            this.addMessage('System', message.message);
                            break;
                        case 'stop_audio':
                            this.stopCurrentAudio();
                            break;
                        case 'error':
                            this.addMessage('System', `‚ùå Error: ${message.text}`);
                            break;
                    }
                } catch (error) {
                    console.error('Failed to parse message:', error);
                }
            }

            getProcessingMessage(status) {
                const messages = {
                    'transcribing': 'üìù Transcribing...',
                    'thinking': 'ü§î Thinking...',
                    'speaking': 'üó£Ô∏è Speaking...',
                    'ready': 'üé§ Ready for input'
                };
                return messages[status] || 'üîÑ Processing...';
            }

            playAudio(base64Data, contentType = 'audio/mpeg', size = 0) {
                try {
                    console.log('üéµ Received audio data:', { length: base64Data.length, contentType, size });

                    // Stop any currently playing audio first
                    if (this.currentAudio) {
                        console.log('üõë Stopping previous audio before starting new one');
                        this.currentAudio.pause();
                        this.currentAudio.currentTime = 0;
                        this.currentAudio = null;
                    }

                    // Convert base64 to binary and create blob
                    const binaryString = atob(base64Data);
                    const bytes = new Uint8Array(binaryString.length);
                    for (let i = 0; i < binaryString.length; i++) {
                        bytes[i] = binaryString.charCodeAt(i);
                    }

                    console.log('üéµ Converted to bytes, length:', bytes.length);

                    // Use server-provided content type, fallback to audio/mpeg
                    const mimeType = contentType && contentType !== 'unknown' ? contentType : 'audio/mpeg';
                    console.log('üéµ Using MIME type:', mimeType);

                    // Create blob and object URL (more reliable than data URLs for large files)
                    const audioBlob = new Blob([bytes], { type: mimeType });
                    const audioUrl = URL.createObjectURL(audioBlob);

                    console.log('üéµ Created blob URL:', audioUrl);

                    const audio = new Audio();
                    audio.crossOrigin = 'anonymous';
                    audio.src = audioUrl;
                    audio.volume = 1.0;  // Max volume for clarity
                    audio.preload = 'metadata';

                    // Track current audio for interruption
                    this.currentAudio = audio;

                    console.log('üéµ Audio element created, setting up listeners...');

                    let hasStartedPlaying = false;

                    const cleanup = () => {
                        URL.revokeObjectURL(audioUrl);
                        console.log('üéµ Cleaned up blob URL');
                    };

                    audio.addEventListener('loadstart', () => {
                        console.log('üéµ Audio loading started');
                    });

                    audio.addEventListener('loadedmetadata', () => {
                        console.log('üéµ Audio metadata loaded, duration:', audio.duration);
                    });

                    audio.addEventListener('canplay', () => {
                        console.log('üéµ Audio can start playing');
                        if (!hasStartedPlaying) {
                            hasStartedPlaying = true;
                            audio.play()
                                .then(() => {
                                    console.log('üîä Auto-play succeeded');
                                })
                                .catch(e => {
                                    console.error('‚ùå Auto-play failed:', e);
                                    this.handlePlaybackError(audio, e);
                                });
                        }
                    });

                    audio.addEventListener('playing', () => {
                        console.log('üîä Audio is now playing');
                        this.addMessage('System', 'üîä Audio response playing');
                    });

                    audio.addEventListener('ended', () => {
                        console.log('üéµ Audio playback ended');
                        this.currentAudio = null;  // Clear current audio reference
                        cleanup();
                    });

                    audio.addEventListener('error', (e) => {
                        console.error('‚ùå Audio error event:', e);
                        console.error('‚ùå Audio error details:', audio.error);
                        this.addMessage('System', '‚ùå Audio playback failed');
                        cleanup();

                        // Try fallback approach
                        this.tryDirectAudioPlay(base64Data);
                    });

                    console.log('üéµ Starting audio load...');
                    audio.load();

                } catch (error) {
                    console.error('‚ùå Audio processing error:', error);
                    this.addMessage('System', `‚ùå Audio processing failed: ${error.message}`);
                }
            }

            handlePlaybackError(audio, error) {
                if (error.name === 'NotAllowedError') {
                    this.addMessage('System', 'üîä Click anywhere to enable audio');

                    const enableAudio = () => {
                        audio.play()
                            .then(() => {
                                console.log('üîä Audio enabled after user interaction');
                                document.removeEventListener('click', enableAudio);
                            })
                            .catch(e => {
                                console.error('‚ùå Still failed to play audio:', e);
                                this.tryDirectAudioPlay(audio.src.split(',')[1]); // Extract base64
                            });
                    };
                    document.addEventListener('click', enableAudio, { once: true });
                } else {
                    this.tryDirectAudioPlay(audio.src.split(',')[1]); // Extract base64
                }
            }

            tryDirectAudioPlay(base64Data) {
                console.log('üîÑ Trying direct audio play with different approaches...');

                // Method 1: Direct data URL
                const dataUrl = `data:audio/mpeg;base64,${base64Data}`;
                const audio1 = new Audio(dataUrl);

                audio1.addEventListener('canplaythrough', () => {
                    console.log('üîä Direct data URL method worked!');
                    audio1.play()
                        .then(() => {
                            this.addMessage('System', 'üîä Audio playing (fallback method)');
                        })
                        .catch(console.error);
                });

                audio1.addEventListener('error', () => {
                    console.log('‚ùå Direct data URL failed, trying audio context...');
                    this.tryWebAudioAPI(base64Data);
                });

                audio1.load();
            }

            async tryWebAudioAPI(base64Data) {
                try {
                    console.log('üîÑ Trying Web Audio API...');

                    const binaryString = atob(base64Data);
                    const bytes = new Uint8Array(binaryString.length);
                    for (let i = 0; i < binaryString.length; i++) {
                        bytes[i] = binaryString.charCodeAt(i);
                    }

                    const audioContext = this.audioContext || new (window.AudioContext || window.webkitAudioContext)();

                    if (audioContext.state === 'suspended') {
                        await audioContext.resume();
                    }

                    const audioBuffer = await audioContext.decodeAudioData(bytes.buffer.slice());
                    const source = audioContext.createBufferSource();
                    source.buffer = audioBuffer;
                    source.connect(audioContext.destination);

                    source.start();
                    console.log('üîä Web Audio API playback started');
                    this.addMessage('System', 'üîä Audio playing (Web Audio API)');

                } catch (error) {
                    console.error('‚ùå Web Audio API failed:', error);
                    this.addMessage('System', '‚ùå All audio playback methods failed');
                }
            }

            stopCurrentAudio() {
                console.log('üõë Stopping current audio due to interruption');

                // Stop current audio
                if (this.currentAudio) {
                    try {
                        this.currentAudio.pause();
                        this.currentAudio.currentTime = 0;
                        this.currentAudio.src = '';  // Clear the source
                        this.currentAudio = null;
                        console.log('üõë Current audio stopped and cleared');
                    } catch (e) {
                        console.error('Error stopping audio:', e);
                    }
                }

                // Stop all audio elements on the page
                const allAudio = document.getElementsByTagName('audio');
                for (let i = 0; i < allAudio.length; i++) {
                    try {
                        allAudio[i].pause();
                        allAudio[i].currentTime = 0;
                        console.log(`üõë Stopped audio element ${i}`);
                    } catch (e) {
                        console.error(`Error stopping audio ${i}:`, e);
                    }
                }

                this.addMessage('System', 'üõë All audio playback stopped');
            }

            tryAlternativeAudioFormat(base64Data) {
                try {
                    console.log('üîÑ Trying alternative formats...');

                    // Try different MIME types
                    const formats = [
                        'data:audio/wav;base64,',
                        'data:audio/mpeg;base64,',
                        'data:audio/mp3;base64,',
                        'data:audio/ogg;base64,',
                        'data:audio/*;base64,'
                    ];

                    for (let i = 0; i < formats.length; i++) {
                        const dataUrl = formats[i] + base64Data;
                        const audio = new Audio(dataUrl);

                        audio.addEventListener('canplaythrough', () => {
                            console.log(`üéµ Format ${i} (${formats[i].split(';')[0]}) works!`);
                            audio.play()
                                .then(() => {
                                    console.log('üîä Alternative format playback succeeded');
                                    this.addMessage('System', 'üîä Audio response playing (alternative format)');
                                })
                                .catch(e => {
                                    console.error('‚ùå Alternative format play failed:', e);
                                });
                        });

                        audio.addEventListener('error', (e) => {
                            console.log(`‚ùå Format ${i} failed:`, e);
                            if (i === formats.length - 1) {
                                this.addMessage('System', '‚ùå All audio formats failed');
                            }
                        });

                        audio.load();

                        // Only try one at a time
                        if (i === 0) {
                            setTimeout(() => {
                                if (audio.readyState === 0) {
                                    console.log('üîÑ First format timed out, trying next...');
                                    this.tryAlternativeAudioFormat(base64Data);
                                }
                            }, 2000);
                            break;
                        }
                    }
                } catch (error) {
                    console.error('‚ùå Alternative format error:', error);
                    this.addMessage('System', '‚ùå No supported audio format found');
                }
            }

            addMessage(sender, text) {
                const messageClass = sender === 'You' ? 'user-message' :
                                   sender === 'Assistant' ? 'assistant-message' : 'system-message';

                const messageHtml = `
                    <div class="message ${messageClass}">
                        <strong>${sender}:</strong> ${text}
                    </div>
                `;

                this.transcript.innerHTML += messageHtml;
                this.transcript.scrollTop = this.transcript.scrollHeight;
            }

            updateStatus(text, connected) {
                this.statusText.textContent = text;
                this.statusEl.className = `status ${connected ? 'connected' : 'disconnected'}`;
            }

            updateVADStatus(text) {
                this.vadText.innerHTML = text;
            }

            updateVolume(level) {
                this.volumeBar.style.width = `${Math.min(100, level)}%`;
            }

            createWavFile(audioData, sampleRate) {
                const length = audioData.length;
                const buffer = new ArrayBuffer(44 + length * 2);
                const view = new DataView(buffer);

                const writeString = (offset, string) => {
                    for (let i = 0; i < string.length; i++) {
                        view.setUint8(offset + i, string.charCodeAt(i));
                    }
                };

                writeString(0, 'RIFF');
                view.setUint32(4, 36 + length * 2, true);
                writeString(8, 'WAVE');
                writeString(12, 'fmt ');
                view.setUint32(16, 16, true);
                view.setUint16(20, 1, true);
                view.setUint16(22, 1, true);
                view.setUint32(24, sampleRate, true);
                view.setUint32(28, sampleRate * 2, true);
                view.setUint16(32, 2, true);
                view.setUint16(34, 16, true);
                writeString(36, 'data');
                view.setUint32(40, length * 2, true);

                let offset = 44;
                for (let i = 0; i < length; i++) {
                    view.setInt16(offset, audioData[i], true);
                    offset += 2;
                }

                return buffer;
            }
        }

        // Initialize the enhanced assistant
        window.addEventListener('DOMContentLoaded', () => {
            new EnhancedVoiceAssistant();
        });
    </script>
</body>
</html>